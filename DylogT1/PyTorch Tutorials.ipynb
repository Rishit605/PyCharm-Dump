{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c25b7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8555c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82440341",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3)\n",
    "y = torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "952c2d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4356, 0.4628, 0.5993],\n",
       "        [2.0171, 0.1217, 0.6163],\n",
       "        [0.9590, 0.0727, 1.2180],\n",
       "        [1.3957, 0.0524, 3.7352],\n",
       "        [2.0483, 0.0604, 1.2842]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.div(x,y)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e92ba1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4356, 0.4628, 0.5993],\n",
       "        [2.0171, 0.1217, 0.6163],\n",
       "        [0.9590, 0.0727, 1.2180],\n",
       "        [1.3957, 0.0524, 3.7352],\n",
       "        [2.0483, 0.0604, 1.2842]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda\")\n",
    "    z = z.to(dev)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab735b",
   "metadata": {},
   "source": [
    "# Calculatin Gradients in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b75fa51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1274,  1.1277, -0.2668], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04df1c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8726, 4.1277, 2.7332], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = x+3\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce8565e",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9837ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.arange(0, 5, dtype=np.float16)\n",
    "Y = np.arange(0, 10, 2, dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dbaa3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be965499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return w*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "66c50ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_pred):\n",
    "    return ((y_pred-y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4a679bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grd(x,y, y_pred):\n",
    "    return np.dot(2*x, y_pred-y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ebb2eb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(forward(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7845769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "n_itr = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "79550ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.2 24.0\n",
      "2 1.6796875 3.838\n",
      "3 1.871875 0.6157\n",
      "4 1.94859375 0.0981\n",
      "5 1.9797070312499998 0.01613\n",
      "6 1.9920703124999999 0.002548\n",
      "7 1.9967578124999998 0.0003662\n",
      "8 1.9984570312499998 4.83e-05\n",
      "9 1.9997460937499998 2.825e-05\n",
      "10 1.9997460937499998 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_itr):\n",
    "    y_preds = forward(X)\n",
    "    \n",
    "    l = loss(Y, y_preds)\n",
    "    \n",
    "    dw = grd(X,Y, y_preds)\n",
    "    \n",
    "    w -= lr * dw\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(epoch+1, w, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa135b",
   "metadata": {},
   "source": [
    "# Using Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ad88f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([0, 1, 2, 3, 4, 5], dtype=torch.float32)\n",
    "Y = torch.tensor([0, 2, 4, 6, 8, 10], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "acce5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8ae618c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "n_itr = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cbd4e269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(1.9840, requires_grad=True) tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "11 tensor(1.9867, requires_grad=True) tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "21 tensor(1.9890, requires_grad=True) tensor(0.0012, grad_fn=<MeanBackward0>)\n",
      "31 tensor(1.9908, requires_grad=True) tensor(0.0008, grad_fn=<MeanBackward0>)\n",
      "41 tensor(1.9924, requires_grad=True) tensor(0.0006, grad_fn=<MeanBackward0>)\n",
      "51 tensor(1.9937, requires_grad=True) tensor(0.0004, grad_fn=<MeanBackward0>)\n",
      "61 tensor(1.9947, requires_grad=True) tensor(0.0003, grad_fn=<MeanBackward0>)\n",
      "71 tensor(1.9956, requires_grad=True) tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "81 tensor(1.9964, requires_grad=True) tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "91 tensor(1.9970, requires_grad=True) tensor(8.6926e-05, grad_fn=<MeanBackward0>)\n",
      "101 tensor(1.9975, requires_grad=True) tensor(6.0038e-05, grad_fn=<MeanBackward0>)\n",
      "111 tensor(1.9979, requires_grad=True) tensor(4.1468e-05, grad_fn=<MeanBackward0>)\n",
      "121 tensor(1.9983, requires_grad=True) tensor(2.8645e-05, grad_fn=<MeanBackward0>)\n",
      "131 tensor(1.9986, requires_grad=True) tensor(1.9788e-05, grad_fn=<MeanBackward0>)\n",
      "141 tensor(1.9988, requires_grad=True) tensor(1.3667e-05, grad_fn=<MeanBackward0>)\n",
      "151 tensor(1.9990, requires_grad=True) tensor(9.4413e-06, grad_fn=<MeanBackward0>)\n",
      "161 tensor(1.9992, requires_grad=True) tensor(6.5206e-06, grad_fn=<MeanBackward0>)\n",
      "171 tensor(1.9993, requires_grad=True) tensor(4.5039e-06, grad_fn=<MeanBackward0>)\n",
      "181 tensor(1.9994, requires_grad=True) tensor(3.1107e-06, grad_fn=<MeanBackward0>)\n",
      "191 tensor(1.9995, requires_grad=True) tensor(2.1483e-06, grad_fn=<MeanBackward0>)\n",
      "201 tensor(1.9996, requires_grad=True) tensor(1.4847e-06, grad_fn=<MeanBackward0>)\n",
      "211 tensor(1.9997, requires_grad=True) tensor(1.0262e-06, grad_fn=<MeanBackward0>)\n",
      "221 tensor(1.9997, requires_grad=True) tensor(7.0864e-07, grad_fn=<MeanBackward0>)\n",
      "231 tensor(1.9998, requires_grad=True) tensor(4.8922e-07, grad_fn=<MeanBackward0>)\n",
      "241 tensor(1.9998, requires_grad=True) tensor(3.3763e-07, grad_fn=<MeanBackward0>)\n",
      "251 tensor(1.9998, requires_grad=True) tensor(2.3357e-07, grad_fn=<MeanBackward0>)\n",
      "261 tensor(1.9999, requires_grad=True) tensor(1.6108e-07, grad_fn=<MeanBackward0>)\n",
      "271 tensor(1.9999, requires_grad=True) tensor(1.1131e-07, grad_fn=<MeanBackward0>)\n",
      "281 tensor(1.9999, requires_grad=True) tensor(7.6834e-08, grad_fn=<MeanBackward0>)\n",
      "291 tensor(1.9999, requires_grad=True) tensor(5.3036e-08, grad_fn=<MeanBackward0>)\n",
      "301 tensor(1.9999, requires_grad=True) tensor(3.6735e-08, grad_fn=<MeanBackward0>)\n",
      "311 tensor(1.9999, requires_grad=True) tensor(2.5372e-08, grad_fn=<MeanBackward0>)\n",
      "321 tensor(2.0000, requires_grad=True) tensor(1.7457e-08, grad_fn=<MeanBackward0>)\n",
      "331 tensor(2.0000, requires_grad=True) tensor(1.2039e-08, grad_fn=<MeanBackward0>)\n",
      "341 tensor(2.0000, requires_grad=True) tensor(8.3358e-09, grad_fn=<MeanBackward0>)\n",
      "351 tensor(2.0000, requires_grad=True) tensor(5.8016e-09, grad_fn=<MeanBackward0>)\n",
      "361 tensor(2.0000, requires_grad=True) tensor(4.0351e-09, grad_fn=<MeanBackward0>)\n",
      "371 tensor(2.0000, requires_grad=True) tensor(2.7740e-09, grad_fn=<MeanBackward0>)\n",
      "381 tensor(2.0000, requires_grad=True) tensor(1.9366e-09, grad_fn=<MeanBackward0>)\n",
      "391 tensor(2.0000, requires_grad=True) tensor(1.3572e-09, grad_fn=<MeanBackward0>)\n",
      "401 tensor(2.0000, requires_grad=True) tensor(8.7437e-10, grad_fn=<MeanBackward0>)\n",
      "411 tensor(2.0000, requires_grad=True) tensor(6.5064e-10, grad_fn=<MeanBackward0>)\n",
      "421 tensor(2.0000, requires_grad=True) tensor(4.8415e-10, grad_fn=<MeanBackward0>)\n",
      "431 tensor(2.0000, requires_grad=True) tensor(3.3931e-10, grad_fn=<MeanBackward0>)\n",
      "441 tensor(2.0000, requires_grad=True) tensor(2.2250e-10, grad_fn=<MeanBackward0>)\n",
      "451 tensor(2.0000, requires_grad=True) tensor(1.2257e-10, grad_fn=<MeanBackward0>)\n",
      "461 tensor(2.0000, requires_grad=True) tensor(9.5225e-11, grad_fn=<MeanBackward0>)\n",
      "471 tensor(2.0000, requires_grad=True) tensor(9.5225e-11, grad_fn=<MeanBackward0>)\n",
      "481 tensor(2.0000, requires_grad=True) tensor(9.5225e-11, grad_fn=<MeanBackward0>)\n",
      "491 tensor(2.0000, requires_grad=True) tensor(9.5225e-11, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_itr):\n",
    "    y_preds = forward(X)\n",
    "    \n",
    "    l = loss(Y, y_preds)\n",
    "    \n",
    "    l.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "    \n",
    "    w.grad.zero_()\n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch+1, w, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c69ac17",
   "metadata": {},
   "source": [
    "# Implimenting Piplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b049cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7c74b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([1, 2, 3, 4, 5, 6], dtype=torch.float32)\n",
    "Y = torch.tensor([0, 2, 4, 6, 8, 10], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dfa83547",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "97b69236",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_r = 1e-2\n",
    "n_itr = 20\n",
    "\n",
    "l = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr = l_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7b24b68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(0.4667, requires_grad=True) tensor(36.6667, grad_fn=<MeanBackward0>)\n",
      "2 tensor(0.7918, requires_grad=True) tensor(18.1919, grad_fn=<MeanBackward0>)\n",
      "3 tensor(1.0183, requires_grad=True) tensor(9.2252, grad_fn=<MeanBackward0>)\n",
      "4 tensor(1.1761, requires_grad=True) tensor(4.8733, grad_fn=<MeanBackward0>)\n",
      "5 tensor(1.2860, requires_grad=True) tensor(2.7611, grad_fn=<MeanBackward0>)\n",
      "6 tensor(1.3626, requires_grad=True) tensor(1.7360, grad_fn=<MeanBackward0>)\n",
      "7 tensor(1.4159, requires_grad=True) tensor(1.2384, grad_fn=<MeanBackward0>)\n",
      "8 tensor(1.4531, requires_grad=True) tensor(0.9970, grad_fn=<MeanBackward0>)\n",
      "9 tensor(1.4790, requires_grad=True) tensor(0.8798, grad_fn=<MeanBackward0>)\n",
      "10 tensor(1.4970, requires_grad=True) tensor(0.8229, grad_fn=<MeanBackward0>)\n",
      "11 tensor(1.5096, requires_grad=True) tensor(0.7953, grad_fn=<MeanBackward0>)\n",
      "12 tensor(1.5184, requires_grad=True) tensor(0.7819, grad_fn=<MeanBackward0>)\n",
      "13 tensor(1.5245, requires_grad=True) tensor(0.7754, grad_fn=<MeanBackward0>)\n",
      "14 tensor(1.5287, requires_grad=True) tensor(0.7722, grad_fn=<MeanBackward0>)\n",
      "15 tensor(1.5317, requires_grad=True) tensor(0.7707, grad_fn=<MeanBackward0>)\n",
      "16 tensor(1.5337, requires_grad=True) tensor(0.7699, grad_fn=<MeanBackward0>)\n",
      "17 tensor(1.5352, requires_grad=True) tensor(0.7696, grad_fn=<MeanBackward0>)\n",
      "18 tensor(1.5362, requires_grad=True) tensor(0.7694, grad_fn=<MeanBackward0>)\n",
      "19 tensor(1.5369, requires_grad=True) tensor(0.7693, grad_fn=<MeanBackward0>)\n",
      "20 tensor(1.5373, requires_grad=True) tensor(0.7693, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_itr):\n",
    "    y_preds = forward(X)\n",
    "    \n",
    "    l = loss(Y, y_preds)\n",
    "    \n",
    "    l.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    w.grad.zero_()\n",
    "    if epoch % 1 == 0:\n",
    "        print(epoch+1, w, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5db8a2",
   "metadata": {},
   "source": [
    "# Linear Regression Using Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "06a63d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "57900ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_n, y_n = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7fe2f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X_n.astype(np.float32))\n",
    "y = torch.from_numpy(y_n.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1) # .view is a built in Torch function used for reshaping the Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e3e531ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samp, n_feat = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "44f60683",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_r = 1e-2\n",
    "n_itr = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "87fd5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "model = nn.Linear(n_feat, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cc6d9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss & OPtimizers\n",
    "\n",
    "crit = nn.MSELoss()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=l_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "93ccb374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2815.481201171875\n",
      "20 1938.275146484375\n",
      "30 1374.9259033203125\n",
      "40 1012.5250244140625\n",
      "50 778.9820556640625\n",
      "60 628.2049560546875\n",
      "70 530.6785278320312\n",
      "80 467.4737854003906\n",
      "90 426.4307861328125\n",
      "100 399.7250061035156\n",
      "110 382.31231689453125\n",
      "120 370.9351501464844\n",
      "130 363.4859619140625\n",
      "140 358.5983581542969\n",
      "150 355.3846740722656\n",
      "160 353.2672119140625\n",
      "170 351.869140625\n",
      "180 350.9441833496094\n",
      "190 350.3309631347656\n",
      "200 349.92364501953125\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_itr):\n",
    "    y_pred = model(X)\n",
    "    loss = crit(y_pred, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    opt.step()\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(epoch+1, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d4ea1615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = model(X).detach().numpy()\n",
    "plt.plot(X_n, y_n, 'ro')\n",
    "plt.plot(X_n, p, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a1dce",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3799aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3d1c212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "930f5a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d49d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /dataset/FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37adee427294b0bafe213f4ba09aee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /dataset/FashionMNIST\\raw\\train-images-idx3-ubyte.gz to /dataset/FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /dataset/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bb64cfb73c4b5c9a0e9cebb56b869d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /dataset/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to /dataset/FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /dataset/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94282aa17bf04481991c73df092362f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /dataset/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to /dataset/FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /dataset/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c7ca7a3f694932b24844da7bff59ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /dataset/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to /dataset/FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('/dataset/',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('/dataset/',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c687a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "test_load = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a151ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "337035a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a203d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        self.pool1=nn.MaxPool2d(2,2)\n",
    "        self.conv2=nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67d2a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ced99",
   "metadata": {},
   "source": [
    "# NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc605d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /dataset/FAshMnist\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e9b0db8dd34148a3a6c0f5eb4f3c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /dataset/FAshMnist\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to /dataset/FAshMnist\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /dataset/FAshMnist\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094246f7e51946b0a49496c32722e686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /dataset/FAshMnist\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to /dataset/FAshMnist\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /dataset/FAshMnist\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3ed1911d0d4d0dbc2c9c01cef1f7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /dataset/FAshMnist\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to /dataset/FAshMnist\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /dataset/FAshMnist\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ffad84c6264fefb5c79fd490059f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /dataset/FAshMnist\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to /dataset/FAshMnist\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.FashionMNIST(\n",
    "    root='/dataset/FAshMnist',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform=None,\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root='/dataset/FAshMnist',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30ef544d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b72cf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f55a0923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_class = train_data.class_to_idx\n",
    "idx_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c51d9a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0,  ..., 3, 0, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf98ad2",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "787e3d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b62a49b9d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, labels = train_data[0]\n",
    "print(image.shape)\n",
    "plt.imshow(image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfbe318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiniBatches\n",
    "\n",
    "BATCH_SIZE=16\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(train_data,shuffle=True, batch_size=BATCH_SIZE, num_workers=2)\n",
    "test_dl = DataLoader(test_data,shuffle=False, batch_size=BATCH_SIZE, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71d59e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOdeling\n",
    "\n",
    "fl_mod = nn.Flatten()\n",
    "\n",
    "\n",
    "class FashMNIST(nn.Module):\n",
    "    def __init__(self, \n",
    "                in_shape: int,\n",
    "                hid_units: int,\n",
    "                out_shape: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Seq = nn.Sequential(\n",
    "            fl_mod,\n",
    "            nn.Linear(in_features=in_shape,\n",
    "                     out_features=hid_units),\n",
    "            nn.Linear(in_features=hid_units,\n",
    "                     out_features=out_shape),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.Seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1d505bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashMNIST(\n",
       "  (Seq): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=8, bias=True)\n",
       "    (2): Linear(in_features=8, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting Model input Parameters\n",
    "\n",
    "model = FashMNIST(in_shape=28*28,\n",
    "                 hid_units=8,\n",
    "                 out_shape=len(class_names)).to(\"cpu\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e45c4171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Seq.1.weight',\n",
       "              tensor([[-0.0263, -0.0004, -0.0185,  ...,  0.0227,  0.0332, -0.0334],\n",
       "                      [ 0.0277,  0.0299, -0.0248,  ..., -0.0299, -0.0199,  0.0221],\n",
       "                      [-0.0209,  0.0099,  0.0035,  ...,  0.0224,  0.0063,  0.0115],\n",
       "                      ...,\n",
       "                      [ 0.0030, -0.0010,  0.0160,  ...,  0.0302,  0.0314, -0.0080],\n",
       "                      [-0.0335, -0.0285, -0.0186,  ..., -0.0327, -0.0324,  0.0145],\n",
       "                      [-0.0190,  0.0204,  0.0182,  ...,  0.0050,  0.0140,  0.0307]])),\n",
       "             ('Seq.1.bias',\n",
       "              tensor([ 0.0034, -0.0352,  0.0051,  0.0323, -0.0012,  0.0091, -0.0161, -0.0060])),\n",
       "             ('Seq.2.weight',\n",
       "              tensor([[-0.2741, -0.3297,  0.0896,  0.3287,  0.2929, -0.1550, -0.1182, -0.1005],\n",
       "                      [-0.0965, -0.1075, -0.0739,  0.0617,  0.1784,  0.1959,  0.1774, -0.3054],\n",
       "                      [ 0.3017,  0.0170, -0.1403,  0.1046,  0.2944,  0.1232,  0.0134, -0.2019],\n",
       "                      [ 0.1429,  0.1772, -0.1670, -0.0123, -0.1965,  0.2654,  0.0012,  0.1460],\n",
       "                      [-0.2192,  0.0824,  0.1362,  0.2279,  0.0066, -0.0699, -0.0927, -0.1269],\n",
       "                      [ 0.1612, -0.0341,  0.2781,  0.1473,  0.0159,  0.2583, -0.1937,  0.3065],\n",
       "                      [ 0.2202,  0.2798, -0.3434,  0.0835,  0.3445,  0.1947, -0.2624,  0.1980],\n",
       "                      [ 0.0728,  0.1990,  0.2085,  0.1172,  0.1176, -0.3310,  0.3281,  0.0269],\n",
       "                      [ 0.0083,  0.3130, -0.0613, -0.0896,  0.1903,  0.0680,  0.0791,  0.0780],\n",
       "                      [ 0.1093, -0.2760, -0.0963, -0.1845, -0.0255,  0.1476, -0.3040, -0.1271]])),\n",
       "             ('Seq.2.bias',\n",
       "              tensor([-0.0300, -0.0430,  0.1978,  0.0550, -0.2710, -0.1202, -0.2895, -0.0873,\n",
       "                      -0.2112,  0.0915]))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f91aca",
   "metadata": {},
   "source": [
    "### We Can Create a seperate helper functions file save it as a .py file and load it later as a pythons script in different models to avoid writing useful light functions again and again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17140d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Loss Function And Optimizers\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(params=model.parameters(),lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1ad00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b015cf4e28db4ff4bc5845879f78e926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating Training Loop\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for ep in tqdm(range(epochs)):\n",
    "    \n",
    "    train_loss = 0\n",
    "    \n",
    "    for bat, (X, y) in enumerate(train_dl):\n",
    "        model.train()\n",
    "        \n",
    "        y_pred = model(X)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if bat % 400 == 0:\n",
    "        print(batch * len(X)/len(train_dl.dataset))\n",
    "    \n",
    "    train_loss /= len(train_dl)\n",
    "    \n",
    "    test_loss, test_acc = 0,0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dl:\n",
    "            \n",
    "            test_pred = model(X_test)\n",
    "            \n",
    "            test_loss += loss_fn(test_pred, y_pred)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae0ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
